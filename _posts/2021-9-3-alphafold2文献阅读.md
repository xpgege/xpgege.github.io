---
layout:     post
title:      alphafold2文献阅读
subtitle:   alphafold2
date:       2021-9-3
author:     xpgege
header-img: img/post-web.jpg
catalog: true
tags:
	- 文献解析
---

# 正文

​	2021年7月15日，DeepMind团队在Nature上发表《Highly accurate protein structure prediction with AlphaFold，并公布了源代码([https://github.com/deepmind/alphafold](https://link.zhihu.com/?target=https%3A//github.com/deepmind/alphafold)，不包含训练代码)

​	本文主要参考https://zhuanlan.zhihu.com/p/396756568和wikipedia、百科、网络搜索等，来源不一一列举，如有侵权，请告知删除。

​	蛋白质对生命至关重要，了解它们的结构可以促进对其功能的系统理解。通过大量的实验，已经确定了大约 100,000 种独特的蛋白质结构，但这仅代表了数十亿已知蛋白质序列中的一小部分。

> **蛋白质结构**是指[蛋白质](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E8%9B%8B%E7%99%BD%E8%B4%A8)分子的空间结构。作为一类重要的[生物大分子](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E7%94%9F%E7%89%A9%E5%A4%A7%E5%88%86%E5%AD%90)，蛋白质主要由[碳](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E7%A2%B3)、[氢](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E6%B0%A2)、[氧](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E6%B0%A7)、[氮](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E6%B0%AE)、[硫](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E7%A1%AB)等[化学元素](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E5%8C%96%E5%AD%A6%E5%85%83%E7%B4%A0)组成。所有蛋白质都是由20种不同的[L型α氨基酸](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E6%B0%A8%E5%9F%BA%E9%85%B8)连接形成的[多聚体](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E5%A4%9A%E8%81%9A%E9%AB%94)，在形成蛋白质后，这些氨基酸又被称为残基。
> 蛋白质一级结构：组成蛋白质多肽链的线性氨基酸序列。
> 蛋白质二级结构：依靠不同氨基酸之间的C=O和N-H基团间的氢键形成的稳定结构，主要为α螺旋和β折叠。
> 蛋白质三级结构：通过多个二级结构元素在三维空间的排列所形成的一个蛋白质分子的三维结构。
> 蛋白质四级结构：用于描述由不同多肽链（亚基）间相互作用形成具有功能的蛋白质复合物分子。

仅根据其氨基酸序列预测蛋白质的三级结构，这是“蛋白质折叠问题”, 50 多年来一直是一个重要的开放性研究问题。尽管最近取得了进展，但现有方法仍远未达到原子级准确度，尤其是当没有可用的同源结构时。

> **同源结构**，那些不同物种因来自共同祖先而具有的相似性**结构**。 例如现代马经较长时间的修饰成为具有一个趾，鼹鼠及其他洞穴动物成为瘤状肢体，大象的肢体成为柱状，这样功能各异的前肢有一个共同来源，他们都来自原始陆生脊椎动物五趾型的肢体。

在这里，我们提供了第一种计算方法，即使在不知道相似结构的情况下，它也可以以原子精度定期预测蛋白质结构。我们在具有挑战性的第 14 次蛋白质结构预测关键评估 (CASP14) 中验证了我们基于神经网络模型的完全重新设计的AlphaFold，在大多数情况下表现出与实验相媲美的准确性，并且大大优于其他方法。支持最新版本的 AlphaFold 是一种新颖的机器学习方法，它将关于蛋白质结构的物理和生物学知识，利用多序列比对，融入深度学习算法的设计中。

> **序列比对**指将两个或多个序列排列在一起，标明其相似之处。序列中可以插入间隔（通常用短横线“-”表示）。对应的相同或相似的符号（在核酸中是A, T(或U), C, G，在蛋白质中是氨基酸残基的单字母表示）排列在同一列上。
> tcctctgcctctgccatcat---caaccccaaagt
> |||| ||| ||||| ||||| ||||||||||||
> tcctgtgcatctgcaatcatgggcaaccccaaagt
> **多序列比对**是成对比对的延伸，是为了在一次比对里面处理多于两条的的序列。多序列比对方法试图比对一个指定序列集合里面的所有序列，这可以帮助确定这些序列的共同区段。进行多序列比对有几种方法，最常用的一种是Clustal程序集，它使用渐进多序列比对算法。Clustal在cladistics中被用来建立进化树，在PSI-BLAST和Hidden Markov model (HMM)中用来建立序列档案以在序列数据库中搜索更远的同源序列。

从蛋白质序列预测蛋白质3D结构的计算方法的发展沿着两条互补的路径前进，分别关注物理相互作用或进化历史。 物理相互作用方案将我们认知的分子驱动力（molecular driving forces）整合到物理热力学或动力学模拟或统计模型逼近中。 虽然理论上非常吸引人，但由于分子模拟的计算难度、蛋白质稳定性的上下文依赖性以及难以产生足够准确的蛋白质物理学模型，这种方法已被证明对即使是中等大小的蛋白质也极具挑战性。 近年来，进化方案提供了一种替代方案，其中蛋白质结构约束来自蛋白质进化历史的生物信息学分析、与已解决结构的同源性和成对进化相关性。

## 预测结果

​	在图 2a 中证明，CASP14 中展示AlphaFold的高准确率扩展到最近大量PDB结构样本，其中所有结构在我们的训练数据截止后都存储在PDB中，并作为完整链进行分析。

​	此外，当主链预测准确时，观察到高侧链准确性（图 2b），并且表明我们预测的局部距离差异测试（pLDDT）置信度可靠地预测了 Ca 局部距离差异测试（lDDT-Cα）准确度相应的预测（图 2c）。我们还发现可以准确估计全局叠加度量模板建模分数 (TM-score)（图 2d）。总体而言，这些验证了 AlphaFold 在 CASP14 蛋白上的高精度和可靠性也可以迁移到最近 PDB 提交的未经整理的数据集中。

![截图录屏_选择区域_20210911150305](https://i.loli.net/2021/09/11/PVQ5Uz4h7XWCKoS.png)



## AlphaFold网络

![截图录屏_选择区域_20210911150640](https://i.loli.net/2021/09/11/q3BiUWtRVJNamHk.png)

​	AlphaFold 通过结合基于蛋白质结构的进化、物理和几何约束的新型神经网络架构和训练程序，大大提高了结构预测的准确性。

​	特别是，我们展示了一种联合嵌入多序列比对 (MSA) 和成对特征的新架构、一种新的输出表示和相关损失函数，可实现准确的端到端结构预测、新的等变注意架构、使用中间损失函数来实现预测的迭代改进，屏蔽 MSA 损失与结构联合训练，使用自蒸馏从未标记的蛋白质序列中学习，以及自我估计准确率。

> > 蒸馏，就是知识蒸馏，将教师网络(teacher network)的知识迁移到学生网络(student network)上，使得学生网络的性能表现如教师网络一般；或者大型模型迁移到小型模型中，小型模型的参数规模小，运行速度快，但性能与大型模型参不多。

AlphaFold 网络使用一级氨基酸序列和同源物的比对序列作为输入，直接预测给定蛋白质的所有重原子的 3-D 坐标



​	该网络包括两个主要阶段。 首先，网络的主干通过我们称为 `Evoformer` 的新型神经网络块的重复层处理输入，以生成 Nseq × Nres 数组（`**Nseq：序列数，Nres：残基数**），表示已处理的 MSA 和 Nres × Nres 数组，表示残基对。 MSA 表示是用原始 MSA 初始化的，但请参阅 附件-方法 1.2.7 了解处理非常深的 MSA 的详细信息。 Evoformer 块包含许多新颖的基于注意力和非基于注意力的组件。 我们在“可解释性”部分展示了证据，表明在 Evoformer 块中早期出现了具体的结构假设并不断完善。 Evoformer 模块的关键创新是在 MSA 内交换信息的新机制和允许直接推理空间和进化关系的配对表示。

​	网络的主干之后是**结构模块**，该模块以蛋白质的每个残基（全局刚体框架）的旋转和平移的形式引入了明确的 3-D 结构。这些表示在简单的状态下初始化，所有旋转设置为一致，所有位置设置为原点，但快速发展和完善，具有精确原子细节的高度准确的蛋白质结构。***网络这一部分的关键创新包括打破链原子结构以允许同时对结构的所有部分进行局部细化，一种新颖的等变变换器允许网络隐式推理未表示的侧链原子，以及一个损失项代替残基的方向正确性的重要权重\***。

​	在结构模块和整个网络中，我们通过反复将最终损失函数应用于输出，然后将输出递归地提供给相同的模块来强化迭代细化的概念。使用整个网络的迭代细化（我们称之为“循环”) 对准确性有显着贡献，而额外的训练时间很少。

​	

## **Evoformer模块**

​	名为 Evoformer（图 1e 和 3a）的网络构建块的关键原理是将蛋白质结构预测视为 3-D 空间中的图推理问题，其中图的边缘由邻近的残基定义。 配对表示的元素编码有关残基之间关系的信息（图 3b）。

​	 MSA 表示的列编码输入序列的各个残基，而行表示这些残基出现的序列。 在这个框架内，我们定义了许多更新操作，这些更新操作应用于每个块中，其中不同的更新操作被串联应用。

![截图录屏_选择区域_20210911153926](https://i.loli.net/2021/09/11/TKLQRV8EPHyatFd.png)

​	**MSA 表示通过在 MSA 序列维度上求和的逐元素外积更新配对表示**。与之前的工作不同，此操作应用于每个块中，而不是在网络中应用一次，这使得从不断发展的 MSA 表示到配对表示的连续通信成为可能。

​	在配对表示中，有两种不同的更新模式。***两者都受到配对表示一致性必要性的启发——为了将氨基酸的配对描述表示为单个 3-D 结构，必须满足许多约束，包括距离上的三角不等式。\***基于这种直觉，我们根据涉及三个不同节点的边三角形来安排对表示的更新操作（图 3c）。特别是，我们向轴向注意力添加了一个额外的 logit 偏差，以包括三角形的“缺失边”，并且我们定义了一个非注意力更新操作“三角形乘法更新”，它使用两条边来更新缺失的第三条边（参见 附件-方法-1.6.5 了解详情）。三角形乘法更新最初是作为注意力更对称且更便宜的替代品而开发的，仅使用注意力或乘法更新的网络都能够产生高精度结构。然而，两个更新的组合更准确。

​	我们还在 MSA 表示中使用了一种轴向注意力的变体。 在 MSA 中的 per-sequence attention 期间，我们从 pair stack 中投射额外的 logits 以偏置 MSA attention。 这通过提供从配对表示返回到 MSA 表示的信息流来关闭循环，确保整个 Evoformer 模块能够完全混合对和 MSA 表示之间的信息，并为结构模块中的结构生成做好准备。



## 端到端结构预测

​	结构模块（图 3d）使用对表示和来自主干的 MSA 表示的原始序列行（“single representation”，“单一表示”）在具体的 3-D 主干结构上运行。 3-D 主干结构表示为 Nres 独立的旋转和平移，每个旋转和平移相对于全局框架（residue gas，“残余气”？，图 3e）。这些旋转和平移，代表 N-Cα-C 原子的几何形状，***优先考虑蛋白质骨架的方向，\***以便每个残基的侧链位置在该框架内受到高度限制。相反，肽键几何形状完全不受约束，并且在应用结构模块期间观察到网络经常违反链约束，因为打破此约束允许对链的所有部分进行局部细化，而无需解决复杂的闭环问题。在微调期间通过违规损失项鼓励满足肽键几何形状。只有在 Amber力场中的梯度下降结构的预测后松弛中才能实现肽键几何形状的精确执行。根据经验，这种最终松弛不会提高模型的准确性，如通过全局距离测试 (GDT) 或 IDDT-Cα34 测量的，但确实消除了分散注意力的立体化学违规而不会损失准确性。

> AMBER力场是在生物[大分子](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%A4%A7%E5%88%86%E5%AD%90)的模拟计算领域有著广泛应用的一个分子力场。AMBER力场的优势在于对生物[大分子](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%A4%A7%E5%88%86%E5%AD%90)的计算，其对小分子体系的计算结果常常不能令人满意。

​	residue gas表示分两个阶段迭代更新（图 3d）。首先，我们称为***不变点注意力\*** ( Point Attention) 的新型几何感知注意操作用于更新 Nres 神经激活集（single representation，“单一表示”）而不改变 3-D 位置，然后对residue gas使用更新的激活。不变点注意力通过在每个残基的局部框架中产生的 3-D 点来增强每个通常的注意力查询、键和值，这样最终值对全局旋转和平移是不变的（参见方法“不变点注意力（IPA）”了解详情)。 3-D 查询和键也对注意力施加了强烈的空间/局部性偏差，这非常适合蛋白质结构的迭代细化。在每个注意力操作和逐元素转换块之后，该模块计算每个主干帧的旋转和平移的更新。这些更新在每个残差的局部框架内的应用使得整体注意力和更新块成为对residue gas的等变操作。

​	侧链 chi 角的预测以及结构的最终每个残基精度 (pLDDT) 是在网络末端的最终激活上使用小的每个残基网络计算的。 TM 分数 (pTM) 的估计值是从成对错误预测中获得的，该预测被计算为最终对表示的线性投影。最后的损失（我们称之为帧对齐点误差（FAPE）（图 3f））将预测的原子位置与许多不同对齐下的真实位置进行比较。对于每个对齐，通过将预测帧 (Rk,tk) 对齐到相应的真实帧来定义，我们计算所有预测原子位置 xi 与真实原子位置的距离。由此产生的 Nframes × Natoms 距离受到限制的 L1 损失的惩罚。这对原子相对于每个残基的局部框架是正确的产生了强烈的偏见，因此在其侧链相互作用方面是正确的，并为 AlphaFold 提供了手性的主要来源（增刊-方法 1.9.3 和增刊-图 9)



## 使用标记和未标记数据进行训练

​	AlphaFold 架构能够仅使用对 PDB 数据的监督学习来训练到高精度，但我们能够使用类似于noisy-student自我蒸馏的方法来提高准确性（见图 4a）。 在这个过程中，我们使用一个训练有素的网络来预测来自 Uniclust30的约 350,000 个不同序列的结构，并将预测结构的新数据集过滤为高置信度子集。 然后，我们使用 PDB 和这个新的预测结构数据集的混合作为训练数据从头开始训练相同的架构，其中各种训练数据增强（例如裁剪和 MSA 子采样）使网络难以重现先前预测的结构。 这种自蒸馏过程有效地利用了未标记的序列数据，并显着提高了所得网络的准确性。

> Self-training是最简单的半监督方法之一，其主要思想是找到一种方法，用未标记的数据集来扩充已标记的数据集。算法流程如下：
> （1）首先，利用已标记的数据来训练一个好的模型，然后使用这个模型对未标记的数据进行标记。
> （2）然后，进行伪标签的生成，因为我们知道，已训练好的模型对未标记数据的所有预测都不可能都是好的，因此对于经典的Self-training，通常是使用分数阈值过滤部分预测，以选择出未标记数据的预测标签的一个子集。
> （3）其次，将生成的伪标签与原始的标记数据相结合，并在合并后数据上进行联合训练。
> （4）整个过程可以重复n次，直到达到收敛。

​	此外，我们随机屏蔽或突变 MSA 中的单个残基，并具有来自 Transformers (BERT) 式目标的双向编码器表示来预测 MSA 序列的屏蔽元素。 这个目标鼓励网络学习解释系统发育和协变关系，而无需将特定的相关统计量硬编码到特征中。 与最近的独立工作相比，BERT 目标是在相同的训练示例上与正常的 PDB 结构损失联合训练的，并且没有进行预训练。



## 解释神经网络

​	为了了解 AlphaFold 如何预测蛋白质结构，我们为网络中的 48 个 Evoformer 块中的每一个训练了一个单独的结构模块，同时保持主网络的所有参数保持不变（补充方法 1.14）。包括我们的回收阶段，这提供了 192 个中间结构的轨迹，每个完整的 Evoformer 块一个，其中每个中间体代表网络对该块最可能结构的信念。在前几个块之后产生的轨迹出奇地平滑，表明 AlphaFold 对结构进行了不断的增量改进，直到它不能再改进为止（见图 4b 的准确度轨迹）。这些轨迹也说明了网络深度的作用。对于非常具有挑战性的蛋白质，如 SARS-CoV-2 Orf8 (T1064)，网络搜索并重新排列多层的二级结构元素，然后再确定一个好的结构。对于 LmrP (T1024) 等其他蛋白质，网络会在前几层内找到最终结构。请参阅增刊-视频 1-4 的 CASP14 目标 T1024、T1044、T1064 和 T1091 的结构轨迹显示了一系列蛋白质大小和难度的清晰迭代构建过程。在补充-方法 1.16 和增刊-图12-13，我们解释了 AlphaFold 层产生的注意力图。

![截图录屏_选择区域_20210911162649](https://i.loli.net/2021/09/11/7cWLsPnUH8aKplZ.png)



## MSA 深度和跨链接触

​	虽然 AlphaFold 在绝大多数沉积的 PDB 结构中具有很高的准确性，但我们注意到仍然存在影响准确性或限制模型适用性的因素。

当平均比对深度小于约 30 个序列时，该模型使用多个序列比对，准确度大幅下降（详见图 5a）。

我们观察到阈值效应，其中 MSA 深度超过约 100 个序列的改进导致小增益。

我们假设需要 MSA 信息在网络的早期阶段粗略地找到正确的结构，但是将该预测细化为高精度模型并不关键取决于 MSA 信息。

我们观察到的另一个实质性限制是，与异型接触的数量相比，AlphaFold 对于链内或同型接触很少的蛋白质要弱得多。这通常发生在较大复合物中的桥接结构域，其中蛋白质的形状几乎完全由与复合物中其他链的相互作用产生。相反，AlphaFold 通常能够为同聚体提供高精度预测，即使链基本上交织在一起（例如图 5b）。我们希望 AlphaFold 的想法很容易适用于预测未来系统中的完整异质复合物，并且这将消除具有大量异质接触的蛋白质链的困难。![截图录屏_选择区域_20210911163824](https://i.loli.net/2021/09/11/3ijSQ1IKlW8E6og.png)



# 补充材料

## 1.1 符号

​	我们用 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bres%7D) 表示输入主序列中的残基数（在训练期间裁剪）， ![[公式]](https://www.zhihu.com/equation?tex=N_%7Btemp%7D) 表示模型中使用的模板数， ![[公式]](https://www.zhihu.com/equation?tex=N_%7Ball%5C_seq%7D) 表示所有可用的 MSA 序列的数量，Nclust 表示 MSA 聚类后的簇数， Nseq 在 MSA 堆栈中处理的序列数（其中 Nseq = Nclust + Ntempl），以及 N extra_seq 未聚类的 MSA 序列数（子采样后，详见 1.2.7 小节）。 这些参数的具体值在训练细节（1.11 小节）中给出。 在模型方面，我们还用 Nblock（第 1.6 小节）表示类 Evoformer 堆栈中的块数，用 N ensemble 表示集成迭代次数（第 1.11.2 小节），用 Ncycle 表示循环迭代次数（第 1.10 小节） .

我们在算法中展示架构细节，我们使用以下约定。我们在封装学习参数时使用大写的运算符名称，例如我们使用 **Linear** 进行具有权重矩阵 W 和偏置向量 b 的线性变换，使用 **LinearNoBias** 进行没有偏置向量的线性变换。我们使用 **LayerNorm** 进行层归一化 [85]，在通道维度上操作，具有可学习的每通道增益和偏差。我们还对随机运算符使用大写名称，例如与 dropout 相关的名称。对于没有参数的函数，我们使用小写的运算符名称，例如sigmoid、softmax、stopgrad。我们用于逐元素乘法，⊗ 用于外积，⊕ 用于外和， ![[公式]](https://www.zhihu.com/equation?tex=a%5E%7BT%7Db) 用于两个向量的点积。索引 i, j, k 总是在残差维度上操作，索引 s, t 在序列维度上操作，索引 h 在注意头维度上操作。通道维度是隐式的，我们以粗体输入通道向量，例如算法对这些向量的集合进行操作，例如我们使用 {zij} 来表示所有的配对表示。

在结构模块中，我们用 T = (R, ![[公式]](https://www.zhihu.com/equation?tex=%5Cbar%7Bt%7D) ) 表示对应于帧的欧几里德变换，其中 R ∈ R3×3 表示旋转, ![[公式]](https://www.zhihu.com/equation?tex=%5Cbar%7Bt%7D) ∈ R3 表示平移分量。 我们使用 ![[公式]](https://www.zhihu.com/equation?tex=%5Ccirc) 运算符来表示对原子位置 ![[公式]](https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D) ∈ R3 的变换应用：

![截图录屏_选择区域_20210911164822](https://i.loli.net/2021/09/11/X3VJTD7PYRucldv.png)

![截图录屏_选择区域_20210911164822](https://i.loli.net/2021/09/11/X3VJTD7PYRucldv.png)

![截图录屏_选择区域_20210911164822](https://i.loli.net/2021/09/11/QkhEF1WHx2ci9dS.png)

## 1.2 data pipline

数据管道是运行 AlphaFold 的第一步。 它需要一个 mmCIF 文件（在**训练模式**下）或一个 FASTA 文件（在**推理模式**下）并为模型生成输入特征。 在训练模式下，单个 mmCIF 文件可以生成多个单独的训练示例，文件中的每个链一个。 数据管道包括以下步骤。

> **mmCIF** 是一种灵活且可扩展的标签值格式，用于表示高分子晶体学信息文件（mmCIF）。 在 mmCIF 字典中定义了一组 mmCIF 标签，用于确定给定 mmCIF 格式文件中存在的信息类别。 字典的结构又由 ddl 定义。 标准 mmCIF 词典 - 自 1997 年被 IUCr 批准以来现在稳定 - 由 Paula M. Fitzgerald、Helen Berman、Phil Bourne、Brian McMahon、Keith Watenpaugh 和 John Westbrook 开创。 更多关于 mmCIF 的信息可以在 RCSB 的 mmCIF 资源页面找到。
> **FASTA**格式是一种用于记录核酸序列或肽序列的文本格式，其中的核酸或氨基酸均以单个字母编码呈现。
> FASTA格式是一种用于记录核酸序列或肽序列的文本格式，其中的核酸或氨基酸均以单个字母编码呈现。如下为FASTA评论区格式一条序列的示例：
> \>gi|31563518|ref|NP_852610.1 ， microtubule-associated proteins 1A/1B light chain 3A isoform b [Homo sapiens]
> MKMRFFSSPCGKAAVDPADRCKEVQQIRDQHPSKIPVIIERYKGEKQLPVLDKTKFLVPDHVNMSELVKI
> IRRRLQLNPTQAFFLLVNQHSMVSVSTPIADIYEQEKDEDGFLYMVYASQETFGFIRENE

### 1.2.1 解析

​	解析输入文件并从中提取基本元数据。 对于 FASTA，这只是序列和名称； 对于 mmCIF，这是序列、原子坐标、发布日期、名称和分辨率。 我们还解决了原子/残基的替代位置，取占有率最大的那个，将 MSE 残基更改为 MET 残基，并修复精氨酸命名的歧义



### 1.2.2 **基因搜索**

使用 **JackHMMER v3.3 [86] 和 HHBlits v3.0-beta.3** [87] 搜索多个遗传数据库。 我们使用 **JackHMMER 和 MGnify** [88]，**JackHMMER 和 UniRef90** [89]，**HHBlits 和 Uniclust30 [90] + BFD**（详见正文方法中的输入和数据源）。 输出的多序列比对 (MSA) 被去重和堆叠。 使用 MGnify 的 JackHMMER 的 MSA 深度限制为 5,000 个序列，使用 UniRef90 的 JackHMMER 限制为 10,000 个序列，而 HHBlits 则不受限制。 以下标志被设置为每个工具的非默认值：

JackHMMER: -N 1 -E 0.0001 --incE 0.0001 --F1 0.0005 --F2 0.00005 --F3 0.0000005.

HHBlits: -n 3 -e 0.001 -realign_max 100000 -maxfilt 100000 -min_prefilter_hits 1000 -maxseq 1000000.



### 1.2.3 模板搜索

通过以下步骤检索输入模型的结构模板：

1. 上一步得到的 UniRef90 MSA 用于使用 HHSearch [91] 搜索 PDB70。为 HHSearch 运行设置为非默认值的唯一标志是 -maxseq 1000000。

2. 在训练期间，我们排除在查询训练结构之后发布的所有模板。我们还过滤掉与输入一级序列相同（或其中的一个子集）或太小（少于 10 个残基或长度少于一级序列的 10%）的模板。

3. 在推理时，我们为模型提供前 4 个模板，按正确对齐残基的预期数量排序（HHSearch 输出的“sum_probs”特征）。在训练时，我们首先将可用模板限制为最多 20 个，其中“sum_probs”最高。然后我们从这组受限制的 n 个模板中随机选择 k 个模板，其中 k = min(Uniform[0, n], 4)。这会在训练期间显示网络潜在的错误模板或根本没有模板，因此网络不能仅依赖于复制模板。



### 1.2.4 训练数据

训练样例有 75% 的概率来自自蒸馏集（参见第 1.3 小节），

而训练样例有 25% 的概率来自蛋白质数据库的已知结构。

 我们在训练期间多次循环这个混合集，并且我们应用许多随机滤波器（第 1.2.5 小节）、

MSA 预处理步骤（第 1.2.6 小节和第 1.2.7 小节）和

残基裁剪（第 1.2.8 小节）。

 这意味着，我们可能会在训练时期观察到不同的目标，使用不同的 MSA 数据样本，也可以裁剪到不同的区域。



### 1.2.5 过滤

以下过滤器应用于训练数据：

• 输入 mmCIF 的分辨率限制为小于 9 Å。 这不是一个非常严格的过滤器，只能去除大约 0.2% 的结构。

• 蛋白质链被接受的概率为 1/512 * max(min(Nres, 512), 256)，其中 Nres 是链的长度。 这重新平衡了长度分布，并使网络更频繁地训练来自较长链的作物。

• 当任何单个氨基酸占输入一级序列的 80% 以上时，序列将被过滤掉。 该过滤器去除了大约 0.8% 的序列。

• 蛋白质链被接受的概率与该链落入的簇的大小成反比。 我们使用与 MMSeqs2 [92] 聚类的蛋白质数据库的 40% 序列同一性簇。



### 1.2.6 MSA block deletion

​	在训练期间，从 MSA 中删除连续的序列块（参见算法 1）。 MSA 按工具分组，并按每个工具的正常输出排序，通常是 e-value。 这意味着相似序列更有可能在 MSA 中相邻，并且块删除更有可能产生多样性，从而移除系统发育的整个分支。



### 1.2.7 MSA 聚类

​	主 Evoformer 模块的计算和峰值内存成本按 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bseq%7D%5E%7B2%7D) × ![[公式]](https://www.zhihu.com/equation?tex=N%5E%7Bres%7D) 缩放，因此纯粹出于计算原因，非常需要减少主 Evoformer 模块中使用的序列数量。 

​	当 MSA 太大（最初是 128 个序列）时，我们这个过程的第一个版本随机选择了一个固定大小的序列子集而没有替换。这个过程有一个明显的缺点，即不包含在随机子集中的序列对预测没有影响。当前的版本是对这个过程的修改，我们仍然选择一个没有替换的随机序列子集作为代表，但是对于完整 MSA 中的每个序列，我们将该序列与代表集中最近的序列相关联（我们称之为“聚类”与随机聚类中心，尽管没有尝试确保聚类中心分布良好）。

​	为了保持固定大小和有界成本属性，因此我们仅使用与每个代表性序列相关的所有序列的氨基酸和缺失频率，并提供这些迷你简介作为除了代表性序列之外的额外特征（我们大致将数字翻了一番每个代表序列的输入特征，而不增加代表序列的数量）。这允许所有序列对最终预测产生一些影响，这似乎是可取的。

​	由于此过程实现了限制计算成本的目标，因此我们没有对该过程的替代方案进行太多实验。 我们尝试了几种方法来鼓励推理时采样序列之间的多样性（例如，偏向于选择彼此远离的代表），但收益非常小甚至没有，因此我们没有进一步深究它们。

具体而言，MSA 使用以下过程进行聚类（分组）：

1. 随机选择Nclust 序列作为MSA 聚类中心，第一个聚类中心始终设置为Query氨基酸序列。

2. 生成一个掩码，使得 MSA 聚类中心的每个位置都有 15% 的概率被包含在掩码中。掩码中包含的 MSA 中的每个元素都按以下方式替换：

   • 以 10% 的概率将氨基酸替换为均匀采样的随机氨基酸。

   • 有 10% 的概率对于给定的位置将氨基酸替换为从 MSA 配置文件中采样的氨基酸

   • 氨基酸有 10% 的可能性不被替换。

   • 氨基酸以 70% 的概率被特殊标记 (masked_msa_token) 替换。这些掩蔽位置是小节 1.9.9 中使用的预测目标。请注意，此掩码在训练时和推理时都使用。

3. 剩余的序列通过汉明距离（忽略被屏蔽的残基和间隙）分配给它们最近的簇。对于每个序列簇，计算几个统计数据，例如每个残基的氨基酸分布。有关完整说明，请参阅表 1 中的“聚类”功能。

4. 使用步骤1中没有被选为聚类中心的MSA序列，对 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bextra%5C_seq%7D) 序列进行不放回随机采样。如果可用的剩余序列少于 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bextra%5C_seq%7D) ，则使用所有这些序列。这些序列形成了表 1 中的“额外”MSA 特征。



### **1.2.8 残基裁剪**

在训练过程中，所有数据中的残基维度按以下方式裁剪。

1. 如 1.11.5 小节所述，小批量以两种模式处理。 在 unclamped loss 模式下，裁剪起始位置从 Uniform[1, n − x + 1] 采样，其中 n 是 seq_length 减去crop_size，x 从 Uniform[0, n] 采样。 在 clamped loss模式下，裁剪位置从 Uniform[1, n + 1] 中采样。

2. 残基维度被裁剪到一个连续的区域，裁剪开始位置在上面定义。 最终的作物大小由 Nres 表示，其具体值在第 1.11 小节中提供。



### **1.2.9 特征化和模型输入**

表 1 中的特征被计算并聚合到模型的以下主要输入中：

• **target_feat** 这是一个大小为[Nres, 21] 的特征，由“aatype”特征组成。

• **Residue_index** 这是一个大小为[Nres] 的特征，由“residue_index”特征组成。

• **msa_feat** 这是一个大小为 [Nclust, Nres, 49] 的特征，通过连接“cluster_msa”、“cluster_has_deletion”、“cluster_deletion_value”、“cluster_deletion_mean”、“cluster_profile”而构建。我们从这个特征中抽取 Ncycle×Nensemble 随机样本，为网络的每个回收/集成迭代提供不同的样本（参见第 1.11.2 小节）。

• **extra_msa_feat** 这是通过连接“extra_msa”、“extra_msa_has_deletion”、“extra_msa_deletion_value”构建的大小为[Nextra_seq, Nres, 25] 的特征。连同上面的“msa_feat”，我们还从这个特征中抽取了 Ncycle × Nensemble 随机样本（参见 1.11.2 小节）。

• **template_pair_feat** 这是一个大小为[Ntempl, Nres, Nres, 88] 的特征，由对残基特征“template_distogram”、“template_unit_vector”以及几个残基特征的串联组成，这些特征被转换为对特征。 “template_aatype”特征是通过平铺和堆叠包含的（这在两个残基方向上进行了两次）。还包括掩码特征“template_pseudo_beta_mask”和“template_backbone_frame_mask”，其中特征 fij = maski · maskj 。

• **template_angle_feat** 这是一个大小为[Ntempl, Nres, 51] 的特征，通过连接以下特征构造而成：“template_aatype”、“template_torsion_angles”、“template_alt_torsion_angles”和“template_torsion_angles_mask”。

![截图录屏_选择区域_20210911175921](/home/xpgege/Desktop/截图录屏_选择区域_20210911175921.png)

![截图录屏_选择区域_20210911175921](https://i.loli.net/2021/09/11/EJ93Xq1Gktg2wKW.png)